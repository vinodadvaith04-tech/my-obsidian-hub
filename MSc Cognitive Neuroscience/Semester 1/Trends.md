### **Fleur Zeldenrust**
#### Biophysics of Neural Computation

### **Hanneke den Ouden**
Learning & Decision-Making

### **Julian Kosciessa**
Cognitive Neurodynamics

### **Alan Sanfey**
Decision Neuroscience

### **Corina Greven**
Positive Developmental Psychopathology

### **Martin Dresler**
Sleep & Memory

### **Hans Rutger Bosker**
Speech Perception in Audiovisual Communication

Speech perception(going from sounds to words)  x  not the same as language comprehension(grammar, pragmatics etc)
Main issue: 
Scan an auditory signal, and match it to already existing sound representations
misheard signals
both in trending sounds as well as pop songs. 

Single signal in isolation isnt enough to fully understand the speech 

Intrinsic variability
	Within-based on the day, sickness, conition of the individual
	Between - age, gender, accent etc. Can cause different people to talk differently
Extrinsic variability 
	Outer noise, background information/distractions

Multiple mappings that a listener uses. 

Distinct phonetic and acoustic cue? to differ similar sounding sounds. 

Changing which [[percept]]? 
High frequency information neurons can get fatigued, such that next when a new sounds is sent only the low frequency can be heard. 

Spectral phenomena(frequency)
Acoustic context(temporal context can bias you)

"Listening brain"
Other knowledge about the person can help understand the speech. 

Bayesian frameworks: Listeners are bayesian ideal observers

![[Pasted image 20251201135306.png]]
Long term probabilities
Short term probabilities 
	thick accent, adaptation but listening harder
	listening to a lisp
	listening with an obstruction
Belief updating model

Those were all the factor in terms of a uni model phenomenon, in terms of only sound

Audiovisual speech perception
"Listening with the eyes"

McGurk effect
Strong effect works even when aware

Audio visual enhancement. 
	facial cues help pick out the words when there are distractions. 
Shared information in A&V
	in timing - seeing the lips move during random background noise helps you point out the something is being said
	in content - when seeing lips closed, assume only some sounds would be produced
![[Pasted image 20251201140223.png]]
pSTS - main area of AV integration

Issues with McGurk
	Everyday convo dont really have these. 
	Variability in stimuli
	Variability in participants
	Doesnt correlate well with other A/V tests

MCGurk effect debate

Audiovisual enhancement - Audio only vs audio with the face. Still debated

Most studies
Integreation of content related information
	Emotions
^This however is language not speech perception

Non verbal cues can be read without speech signals
Hence its difficult to operationalize 'audio visual integration'
Which signals to choose to performs audio visual integration

Speech gestures arent random, but carefully planned
gestures only work with speech, unique for it. eg beat gestures
ubiquitous(common)
Timed based on sylibles 

All languages have stress. 
	stress sylables differ based on languages
Measured by amplitude, pitch, as well as hand trajectory, timing of it all

Several gestures all peak at the stress or emphasis or 0. 

Peak deceleration(apex)
Your voice, biomechanically changes based on your movement, voice body coupling 
Subtle pressure that surface in the acoustic signals. Not only is the gesture produced due to speech, but also the movement changes the signals produced. 

Gesture speech coupling
Variability
	stress languages vs tonal languages
	native and non native speaker
Hand signals often move as the native language, even tho pronunciation is in another language. Stress is before or after in their. native language. 

Higher activity in LIFG and MTG compared to async beat gestures

Maran et al., 2025 - even tho the participant knows, they still recognise the pattern, and we recognise only gestures we are familiar with. 

Effects on lexical stress
vowel length
word segmentation

Manual McGurk - audiovisual integration?(not the same as the classic)
guides implicit perception even in passive watching
Good index
Unique to humans





### **Floris de Lange**
Predictive brain


### **Timo van Kerkoerle
Top-down Vision

### **Harold Bekkering**
Learning & motivation
Learning
Brain is a predictive machine that learns from prediction error
Predictive coding, sensory area meets the information coming from higher brain areas. 



### **Linda Geerligs**
Dynamic & Naturalistic Cognitive Neuroscience

### **Carys Evans**
Cognitive Neuromodulation

### **Linda Drijvers**
The Communicative Brain

### **Marijn Kuijpers**
Molecular Mechanism of Neurodegeneration

### **Marius Peelen**
Visual Cognitive Neuroscience

### **Carolina de Weerth**
Psychobiology of Early Development
